# -*- coding: utf-8 -*-
"""GPT2WIKIPULL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZzJUNNivdrIOysP-uF59-cgrkNbEhlXf
"""



import requests

def fetch_wikipedia_content(query):
    """
    Fetches the summary of a Wikipedia page for a given query.

    Parameters:
    - query: The search term to query Wikipedia for.

    Returns:
    A string containing the summary of the Wikipedia page.
    """
    URL = f"https://en.wikipedia.org/api/rest_v1/page/summary/{query}"
    response = requests.get(URL)

    if response.status_code == 200:
        data = response.json()
        print(data)
        return data['extract']
    else:
        return "Could not fetch data from Wikipedia."

from transformers import pipeline, set_seed

def analyze_with_gpt2(content):
    """
    Uses GPT-2 to generate a course plan based on the given content.

    Parameters:
    - content: The content fetched from Wikipedia.

    Returns:
    A string containing a course plan generated by GPT-2.
    """
    generator = pipeline('text-generation', model='gpt2')
    set_seed(42)
    results = generator(f"Generate a 15 week course plan based on this content: {content}", max_length=500, num_return_sequences=1)
    return results[0]['generated_text']

def main():
    query = input("Enter a topic to generate a course plan: ")
    wiki_content = fetch_wikipedia_content(query)
    print("\nFetching Wikipedia content... Done.\n")

    print("Generating course plan using GPT-2...\n")
    course_plan = analyze_with_gpt2(wiki_content[:1000])  # We limit the content to avoid overwhelming GPT-2
    print(course_plan)

if __name__ == "__main__":
    main()
