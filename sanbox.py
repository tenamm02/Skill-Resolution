# -*- coding: utf-8 -*-
"""GPT2WIKIPULL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZzJUNNivdrIOysP-uF59-cgrkNbEhlXf
"""

import requests
import arxiv  # You'll need to install this library using pip

def fetch_arxiv_content(query):
    """
    Fetches the summary of an arXiv paper for a given query.

    Parameters:
    - query: The search term to query arXiv for.

    Returns:
    A string containing the summary of the arXiv paper.
    """
    search = arxiv.Search(
      query = query,
      max_results = 1,
      sort_by = arxiv.SortCriterion.Relevance
    )

    for result in search.results():
        return result.summary

from transformers import pipeline, set_seed

def analyze_with_gpt2(content):
    """
    Uses GPT-2 to generate a course plan with structured content and questions.

    Parameters:
    - content: The content fetched from Wikipedia.

    Returns:
    A string containing a structured course plan generated by GPT-2.
    """
    generator = pipeline('text-generation', model='gpt2')
    set_seed(42)

    # Split content into sections
    sections = content.split('\n\n')

    # Initialize the course plan
    course_plan = ""

    # Iterate over sections and add structured content
    for section in sections:
        # Generate a heading for the section
        course_plan += f"\n\n## {section[:50]}"  # Limit heading length to 50 characters

        # Generate questions related to the section
        questions = generator(f"What are some questions related to {section[:50]}?", max_length=100,
                              num_return_sequences=3)
        course_plan += "\n\n### Questions:"
        for q in questions:
            course_plan += f"\n- {q['generated_text'].strip()}"

        # Generate a brief summary of the section
        summary = generator(f"Summarize the section: {section[:50]}", max_length=200, num_return_sequences=1)
        course_plan += f"\n\n### Summary:\n{summary[0]['generated_text']}"

    return course_plan

def main():
    query = input("Enter a topic to generate a course plan: ")
    arxiv_content = fetch_arxiv_content(query)
    print("\nFetching arXiv content... Done.\n")

    print("Generating course plan using GPT-2...\n")
    course_plan = analyze_with_gpt2(arxiv_content[:1000])  # We limit the content to avoid overwhelming GPT-2
    print(course_plan)

if __name__ == "__main__":
    main()
